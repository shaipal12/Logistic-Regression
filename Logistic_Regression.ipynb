{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, cohen_kappa_score, precision_recall_curve, auc\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import load_iris\n"
      ],
      "metadata": {
        "id": "Q6ItL3Byu4U3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n",
        "# Load dataset (Iris dataset)\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = (iris.target == 2).astype(int)  # Convert to binary classification (class 2 vs others)\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bIgGFk5ydDt",
        "outputId": "a9e0a417-0916-434e-a45a-13a7590d2dab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with L1 penalty (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uagCrWGc3-Ug",
        "outputId": "1fa20107-7fa1-4fd6-9518-9c48bad45e67"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients.\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with L2 penalty (Ridge)\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', C=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print model coefficients\n",
        "print('Model Coefficients:', model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANYgff9y4Xzw",
        "outputId": "03b2ee70-f410-4667-abd5-5811f05cff84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8550\n",
            "Model Coefficients: [[ 0.09313067 -0.57234579  0.22858796  0.10022439 -0.02330397  1.62784037\n",
            "  -0.0850261  -0.01814307 -0.02321708  0.00901688  0.20647711  0.44047538\n",
            "   0.03047508  0.13712753 -0.92389495  0.08010283  0.07022722 -0.14921618\n",
            "  -1.19160279  0.10917366]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with Elastic Net penalty\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print model coefficients\n",
        "print('Model Coefficients:', model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aci3eb3Y408m",
        "outputId": "4eb7015b-b9e5-4a28-e8ee-fa97b3713c28"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8550\n",
            "Model Coefficients: [[ 0.08772963 -0.18558237  0.22361164  0.09430098 -0.01741445  1.8970713\n",
            "  -0.08039025 -0.01217671 -0.01652056  0.00435164  0.20118399  0.43742187\n",
            "   0.0253483   0.13111478 -0.68549696  0.07237994  0.06413238 -0.14336783\n",
            "  -1.19241539  0.10471421]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
        "\n",
        "# Generate a synthetic dataset for multiclass classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=3, n_informative=15, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model for multiclass classification using one-vs-rest (OvR)\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0, multi_class='ovr', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print model coefficients\n",
        "print('Model Coefficients:', model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2RAieCR5I27",
        "outputId": "81ecea93-e9ed-452d-98e2-aa1e42a71077"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.6050\n",
            "Model Coefficients: [[-5.45699970e-01  3.12580245e-01  0.00000000e+00  4.54118939e-01\n",
            "   4.18927229e-01 -2.47299816e-02  3.11987554e-02  1.23571505e-01\n",
            "   1.21256014e-01 -1.60504564e-02  8.04285072e-02 -7.35365243e-02\n",
            "  -6.20196212e-01 -2.39700588e-01 -7.35223208e-01  0.00000000e+00\n",
            "   4.10145650e-01  9.22613739e-02 -2.56893096e-01 -1.36101625e-01]\n",
            " [ 1.46762334e+00  2.56785389e-01 -2.25455138e-04 -1.01937832e+00\n",
            "   3.14366998e-01  1.04810805e-01  1.52393834e-01 -1.35283645e-01\n",
            "   3.72371294e-01  0.00000000e+00  3.57950867e-01  7.40472692e-02\n",
            "   2.12203283e-01  9.89482335e-02  2.38652095e-02 -1.22525988e-01\n",
            "   5.22487886e-01  1.03501248e-02  0.00000000e+00  4.46672898e-01]\n",
            " [-8.24640828e-01 -4.96068478e-01 -2.58012518e-01  2.89035205e-01\n",
            "  -5.37236829e-01 -7.53692739e-02 -3.64023900e-01  1.77821522e-02\n",
            "  -3.60381761e-01  3.86701301e-01 -4.99557518e-01  7.40597712e-02\n",
            "   3.00755696e-01  3.01274403e-01  2.53591009e-01  0.00000000e+00\n",
            "  -8.00700187e-01 -4.70225966e-02  4.42994238e-01  0.00000000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n",
        "# Generate a synthetic dataset for multiclass classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=3, n_informative=15, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'l1_ratio': [0.5]  # Only relevant for elasticnet\n",
        "}\n",
        "\n",
        "# Train Logistic Regression model with GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(solver='saga', multi_class='ovr', random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Best Parameters: {best_params}')\n",
        "print(f'Model Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print model coefficients\n",
        "print('Model Coefficients:', best_model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOFbsak15Zio",
        "outputId": "519d4a58-d080-4354-9012-000093b7785f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'l1_ratio': 0.5, 'penalty': 'l2'}\n",
            "Model Accuracy: 0.6150\n",
            "Model Coefficients: [[-4.39493820e-01  3.04718635e-01  1.27041389e-01  4.33739258e-01\n",
            "   2.49808735e-01 -2.59508855e-02  1.32374387e-01  1.18234986e-01\n",
            "   1.56587088e-01 -2.35416095e-01  1.42239901e-01 -7.30417330e-02\n",
            "  -4.19365868e-01 -2.78151712e-01 -4.05151939e-01  2.39872584e-01\n",
            "   2.88434738e-01  1.56644647e-01 -2.70357313e-01 -2.83964771e-01]\n",
            " [ 1.21156340e+00  1.87674424e-01  7.87069338e-04 -7.79787115e-01\n",
            "   2.67829013e-01  8.92319522e-02  2.07675690e-01 -1.23811213e-01\n",
            "   3.06056694e-01 -6.40215731e-04  3.50290761e-01  5.98292758e-02\n",
            "   1.48003062e-01  7.43699782e-02  1.79129659e-01 -2.37069014e-01\n",
            "   4.07841892e-01 -4.84398911e-02 -7.21579289e-02  3.67186196e-01]\n",
            " [-6.94665548e-01 -4.20501777e-01 -1.92002864e-01  2.76295959e-01\n",
            "  -4.96875801e-01 -6.78061752e-02 -3.20348506e-01  1.37874890e-02\n",
            "  -2.94457582e-01  3.15980682e-01 -4.53981891e-01  7.13606710e-02\n",
            "   2.96370721e-01  2.72510978e-01  2.81525342e-01 -3.32050055e-03\n",
            "  -6.77820404e-01 -4.60188468e-02  3.48255764e-01 -3.59560040e-02]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n",
        "# Generate a synthetic dataset for multiclass classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=3, n_informative=15, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(solver='saga', multi_class='ovr', penalty='l2', C=1.0, random_state=42)\n",
        "\n",
        "# Perform Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Calculate average accuracy\n",
        "average_accuracy = np.mean(scores)\n",
        "print(f'Average Accuracy: {average_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzL-Fpt-6Va1",
        "outputId": "8dd4f0fe-2fde-40fe-c3fa-4d7221a5a08b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "# Load dataset from CSV file\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Assume the last column is the target variable\n",
        "y = df.iloc[:, -1]\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_dist = {\n",
        "    'C': np.logspace(-4, 4, 10),\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'l1_ratio': [0.5]  # Only relevant for elasticnet\n",
        "}\n",
        "\n",
        "# Train Logistic Regression model with RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(LogisticRegression(multi_class='ovr', random_state=42), param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best estimator\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Make predictions using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Best Parameters: {best_params}')\n",
        "print(f'Model Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "GrfxLC9T7NlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "# Load dataset from CSV file\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Assume the last column is the target variable\n",
        "y = df.iloc[:, -1]\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model for multiclass classification using One-vs-One (OvO)\n",
        "model = LogisticRegression(multi_class='ovo', solver='lbfgs', penalty='l2', C=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "vTyw6LP37cfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "# Generate synthetic binary classification data\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "oLUCFg0p7o3h",
        "outputId": "65856f8f-18a1-4aad-d7ff-70eb851d0508"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.84      0.82        89\n",
            "           1       0.87      0.82      0.84       111\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.83      0.83      0.83       200\n",
            "weighted avg       0.83      0.83      0.83       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(1000, 5)\n",
        "y = np.random.randint(0, 2, 1000)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwTpYaIf88WH",
        "outputId": "0a3f7d2d-6f7e-4e38-b09d-6debce8cddc6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.54\n",
            "Recall: 0.74\n",
            "F1-Score: 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "# Generate synthetic imbalanced dataset\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(1000, 5)\n",
        "y = np.random.choice([0, 1], size=1000, p=[0.9, 0.1])  # Imbalanced dataset\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Compute class weights\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: weights[i] for i in range(len(weights))}\n",
        "\n",
        "# Train Logistic Regression model with class weights\n",
        "model = LogisticRegression(class_weight=class_weights)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LtgYvtt9aLM",
        "outputId": "d785ddfe-c5b2-4d59-9c60-cc808c1ff40f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.08\n",
            "Recall: 0.41\n",
            "F1-Score: 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = (iris.target != 0).astype(int)  # Binary classification (Setosa vs. Non-Setosa)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression without scaling\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with scaling\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy with scaling: {accuracy_with_scaling:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaBVEtcroCyt",
        "outputId": "979d2a74-c95b-480b-d2cc-c0a2d6080e5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with scaling: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC scor.\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = (iris.target != 0).astype(int)  # Binary classification (Setosa vs. Non-Setosa)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with scaling\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "y_pred_prob = model_scaled.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "print(f\"Accuracy with scaling: {accuracy_with_scaling:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag1AkegEpZKU",
        "outputId": "ff561681-346a-46c5-a2ba-c4a6fe3bd289"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaling: 1.0000\n",
            "ROC-AUC Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = (iris.target != 0).astype(int)  # Binary classification (Setosa vs. Non-Setosa)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with custom learning rate (C=0.5)\n",
        "model_scaled = LogisticRegression(C=0.5)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "y_pred_prob = model_scaled.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "print(f\"Accuracy with scaling (C=0.5): {accuracy_with_scaling:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWstCcEXpz-g",
        "outputId": "013635ca-e5d0-46d6-87e8-ad1ed35b1bbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaling (C=0.5): 1.0000\n",
            "ROC-AUC Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = (iris.target != 0).astype(int)  # Binary classification (Setosa vs. Non-Setosa)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with custom learning rate (C=0.5)\n",
        "model_scaled = LogisticRegression(C=0.5)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "y_pred_prob = model_scaled.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "print(f\"Accuracy with scaling (C=0.5): {accuracy_with_scaling:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# Identify important features\n",
        "feature_importance = pd.DataFrame({'Feature': iris.feature_names, 'Coefficient': model_scaled.coef_[0]})\n",
        "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)\n",
        "print(\"\\nFeature Importance based on Coefficients:\")\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6C0duinq1Wv",
        "outputId": "b0fb83d2-0ce1-4ab7-ccbf-3dc2c4fa3ac3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaling (C=0.5): 1.0000\n",
            "ROC-AUC Score: 1.0000\n",
            "\n",
            "Feature Importance based on Coefficients:\n",
            "             Feature  Coefficient\n",
            "2  petal length (cm)     1.402280\n",
            "3   petal width (cm)     1.298197\n",
            "0  sepal length (cm)     0.865919\n",
            "1   sepal width (cm)    -1.019791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score.\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = (iris.target != 0).astype(int)  # Binary classification (Setosa vs. Non-Setosa)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with custom learning rate (C=0.5)\n",
        "model_scaled = LogisticRegression(C=0.5)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "y_pred_prob = model_scaled.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy with scaling (C=0.5): {accuracy_with_scaling:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "\n",
        "# Identify important features\n",
        "feature_importance = pd.DataFrame({'Feature': iris.feature_names, 'Coefficient': model_scaled.coef_[0]})\n",
        "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)\n",
        "print(\"\\nFeature Importance based on Coefficients:\")\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guBKKte3rK5z",
        "outputId": "3022c10d-0a39-4117-beef-baa555946301"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaling (C=0.5): 1.0000\n",
            "ROC-AUC Score: 1.0000\n",
            "Cohen's Kappa Score: 1.0000\n",
            "\n",
            "Feature Importance based on Coefficients:\n",
            "             Feature  Coefficient\n",
            "2  petal length (cm)     1.402280\n",
            "3   petal width (cm)     1.298197\n",
            "0  sepal length (cm)     0.865919\n",
            "1   sepal width (cm)    -1.019791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classificatio.\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = (iris.target != 0).astype(int)  # Binary classification (Setosa vs. Non-Setosa)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with custom learning rate (C=0.5)\n",
        "model_scaled = LogisticRegression(C=0.5)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "y_pred_prob = model_scaled.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy with scaling (C=0.5): {accuracy_with_scaling:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "\n",
        "# Identify important features\n",
        "feature_importance = pd.DataFrame({'Feature': iris.feature_names, 'Coefficient': model_scaled.coef_[0]})\n",
        "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)\n",
        "print(\"\\nFeature Importance based on Coefficients:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "IzEwxTUCvRt2",
        "outputId": "f1e776fd-511a-4758-d253-7a16279df54c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaling (C=0.5): 1.0000\n",
            "ROC-AUC Score: 1.0000\n",
            "Cohen's Kappa Score: 1.0000\n",
            "\n",
            "Feature Importance based on Coefficients:\n",
            "             Feature  Coefficient\n",
            "2  petal length (cm)     1.402280\n",
            "3   petal width (cm)     1.298197\n",
            "0  sepal length (cm)     0.865919\n",
            "1   sepal width (cm)    -1.019791\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASttJREFUeJzt3XlclWX+//H3AVlVQGMTI3F3NNPC5ItpZqG45KjTlKkpWlZuMyWZaamUlbSaVqbluE1jI2naWBpmlJaJWW6Tua+YCS4FKCoI5/r90c8znQADBI54v56Px/14eK77uq/zuS/B8/bejs0YYwQAAGAhbq4uAAAAoLIRgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAUafDgwYqIiCjVNmvWrJHNZtOaNWsqpKaq7rbbbtNtt93meH3o0CHZbDbNnz/fZTUBVkUAAq4Q8+fPl81mcyze3t5q0qSJRo0apYyMDFeXd8W7GCYuLm5ubqpdu7a6deum1NRUV5dXLjIyMjRmzBg1a9ZMvr6+ql69uiIjI/Xcc88pMzPT1eUBVUo1VxcAwNnkyZNVv359nT9/XuvWrdPMmTO1cuVKbd++Xb6+vpVWx+zZs2W320u1za233qpz587J09Ozgqr6Y/369VP37t1VUFCgPXv26K233lKnTp307bffqmXLli6r63J9++236t69u86cOaP77rtPkZGRkqTvvvtOL7zwgr788kt9+umnLq4SqDoIQMAVplu3bmrTpo0kaejQobrmmms0depU/ec//1G/fv2K3CYnJ0fVq1cv1zo8PDxKvY2bm5u8vb3LtY7Suummm3Tfffc5Xnfo0EHdunXTzJkz9dZbb7mwsrLLzMxUnz595O7uri1btqhZs2ZO659//nnNnj27XN6rIn6WgCsRp8CAK9ztt98uSTp48KCkX6/NqVGjhvbv36/u3burZs2aGjBggCTJbrdr2rRpatGihby9vRUSEqKHH35Yv/zyS6FxP/nkE3Xs2FE1a9aUn5+fbr75Zr333nuO9UVdA7Ro0SJFRkY6tmnZsqWmT5/uWF/cNUCLFy9WZGSkfHx8FBgYqPvuu09Hjx516nNxv44eParevXurRo0aCgoK0pgxY1RQUFDm+evQoYMkaf/+/U7tmZmZevTRRxUeHi4vLy81atRIL774YqGjXna7XdOnT1fLli3l7e2toKAgde3aVd99952jz7x583T77bcrODhYXl5eat68uWbOnFnmmn/v7bff1tGjRzV16tRC4UeSQkJCNGHCBMdrm82mp59+ulC/iIgIDR482PH64mnXtWvXasSIEQoODta1116rJUuWONqLqsVms2n79u2Otl27dumvf/2rateuLW9vb7Vp00bLly+/vJ0GKhhHgIAr3MUP7muuucbRlp+fr9jYWLVv316vvPKK49TYww8/rPnz52vIkCH6+9//roMHD+rNN9/Uli1b9PXXXzuO6syfP1/333+/WrRoofHjxysgIEBbtmxRcnKy+vfvX2Qdq1evVr9+/XTHHXfoxRdflCTt3LlTX3/9tR555JFi679Yz80336zExERlZGRo+vTp+vrrr7VlyxYFBAQ4+hYUFCg2NlZRUVF65ZVX9Nlnn+nVV19Vw4YNNXz48DLN36FDhyRJtWrVcrSdPXtWHTt21NGjR/Xwww/ruuuu0/r16zV+/HgdO3ZM06ZNc/R94IEHNH/+fHXr1k1Dhw5Vfn6+vvrqK23YsMFxpG7mzJlq0aKF/vznP6tatWr66KOPNGLECNntdo0cObJMdf/W8uXL5ePjo7/+9a+XPVZRRowYoaCgIE2aNEk5OTnq0aOHatSooffff18dO3Z06puUlKQWLVro+uuvlyT98MMPuuWWW1S3bl2NGzdO1atX1/vvv6/evXvrgw8+UJ8+fSqkZuCyGQBXhHnz5hlJ5rPPPjMnTpwwR44cMYsWLTLXXHON8fHxMT/++KMxxpi4uDgjyYwbN85p+6+++spIMgsXLnRqT05OdmrPzMw0NWvWNFFRUebcuXNOfe12u+PPcXFxpl69eo7XjzzyiPHz8zP5+fnF7sMXX3xhJJkvvvjCGGNMXl6eCQ4ONtdff73Te3388cdGkpk0aZLT+0kykydPdhrzxhtvNJGRkcW+50UHDx40kswzzzxjTpw4YdLT081XX31lbr75ZiPJLF682NH32WefNdWrVzd79uxxGmPcuHHG3d3dpKWlGWOM+fzzz40k8/e//73Q+/12rs6ePVtofWxsrGnQoIFTW8eOHU3Hjh0L1Txv3rxL7lutWrVMq1atLtnntySZhISEQu316tUzcXFxjtcXf+bat29f6O+1X79+Jjg42Kn92LFjxs3Nzenv6I477jAtW7Y058+fd7TZ7XbTrl0707hx4xLXDFQ2ToEBV5iYmBgFBQUpPDxc9957r2rUqKFly5apbt26Tv1+f0Rk8eLF8vf3V+fOnXXy5EnHEhkZqRo1auiLL76Q9OuRnNOnT2vcuHGFrtex2WzF1hUQEKCcnBytXr26xPvy3Xff6fjx4xoxYoTTe/Xo0UPNmjXTihUrCm0zbNgwp9cdOnTQgQMHSvyeCQkJCgoKUmhoqDp06KCdO3fq1VdfdTp6snjxYnXo0EG1atVymquYmBgVFBToyy+/lCR98MEHstlsSkhIKPQ+v50rHx8fx5+zsrJ08uRJdezYUQcOHFBWVlaJay9Odna2atasednjFOfBBx+Uu7u7U1vfvn11/Phxp9OZS5Yskd1uV9++fSVJP//8sz7//HPdc889On36tGMeT506pdjYWO3du7fQqU7gSsEpMOAKM2PGDDVp0kTVqlVTSEiImjZtKjc35/+rVKtWTddee61T2969e5WVlaXg4OAixz1+/Lik/51Su3gKo6RGjBih999/X926dVPdunXVpUsX3XPPPeratWux2xw+fFiS1LRp00LrmjVrpnXr1jm1XbzG5rdq1arldA3TiRMnnK4JqlGjhmrUqOF4/dBDD+nuu+/W+fPn9fnnn+v1118vdA3R3r179d///rfQe13027kKCwtT7dq1i91HSfr666+VkJCg1NRUnT171mldVlaW/P39L7n9H/Hz89Pp06cva4xLqV+/fqG2rl27yt/fX0lJSbrjjjsk/Xr6q3Xr1mrSpIkkad++fTLGaOLEiZo4cWKRYx8/frxQeAeuBAQg4ArTtm1bx7UlxfHy8ioUiux2u4KDg7Vw4cIitynuw76kgoODtXXrVq1atUqffPKJPvnkE82bN0+DBg3SggULLmvsi35/FKIoN998syNYSb8e8fntBb+NGzdWTEyMJOnOO++Uu7u7xo0bp06dOjnm1W63q3Pnzho7dmyR73HxA74k9u/frzvuuEPNmjXT1KlTFR4eLk9PT61cuVKvvfZaqR8lUJRmzZpp69atysvLu6xHDBR3Mflvj2Bd5OXlpd69e2vZsmV66623lJGRoa+//lpTpkxx9Lm4b2PGjFFsbGyRYzdq1KjM9QIViQAEXCUaNmyozz77TLfcckuRH2i/7SdJ27dvL/WHk6enp3r27KmePXvKbrdrxIgRevvttzVx4sQix6pXr54kaffu3Y672S7avXu3Y31pLFy4UOfOnXO8btCgwSX7P/XUU5o9e7YmTJig5ORkSb/OwZkzZxxBqTgNGzbUqlWr9PPPPxd7FOijjz5Sbm6uli9fruuuu87RfvGUY3no2bOnUlNT9cEHHxT7KITfqlWrVqEHI+bl5enYsWOlet++fftqwYIFSklJ0c6dO2WMcZz+kv439x4eHn84l8CVhmuAgKvEPffco4KCAj377LOF1uXn5zs+ELt06aKaNWsqMTFR58+fd+pnjCl2/FOnTjm9dnNz0w033CBJys3NLXKbNm3aKDg4WLNmzXLq88knn2jnzp3q0aNHifbtt2655RbFxMQ4lj8KQAEBAXr44Ye1atUqbd26VdKvc5WamqpVq1YV6p+Zman8/HxJ0l133SVjjJ555plC/S7O1cWjVr+du6ysLM2bN6/U+1acYcOGqU6dOnrssce0Z8+eQuuPHz+u5557zvG6YcOGjuuYLnrnnXdK/TiBmJgY1a5dW0lJSUpKSlLbtm2dTpcFBwfrtttu09tvv11kuDpx4kSp3g+oTBwBAq4SHTt21MMPP6zExERt3bpVXbp0kYeHh/bu3avFixdr+vTp+utf/yo/Pz+99tprGjp0qG6++Wb1799ftWrV0rZt23T27NliT2cNHTpUP//8s26//XZde+21Onz4sN544w21bt1af/rTn4rcxsPDQy+++KKGDBmijh07ql+/fo7b4CMiIjR69OiKnBKHRx55RNOmTdMLL7ygRYsW6fHHH9fy5ct15513avDgwYqMjFROTo6+//57LVmyRIcOHVJgYKA6deqkgQMH6vXXX9fevXvVtWtX2e12ffXVV+rUqZNGjRqlLl26OI6MPfzwwzpz5oxmz56t4ODgUh9xKU6tWrW0bNkyde/eXa1bt3Z6EvTmzZv173//W9HR0Y7+Q4cO1bBhw3TXXXepc+fO2rZtm1atWqXAwMBSva+Hh4f+8pe/aNGiRcrJydErr7xSqM+MGTPUvn17tWzZUg8++KAaNGigjIwMpaam6scff9S2bdsub+eBiuLKW9AA/M/FW5K//fbbS/aLi4sz1atXL3b9O++8YyIjI42Pj4+pWbOmadmypRk7dqz56aefnPotX77ctGvXzvj4+Bg/Pz/Ttm1b8+9//9vpfX57G/ySJUtMly5dTHBwsPH09DTXXXedefjhh82xY8ccfX5/G/xFSUlJ5sYbbzReXl6mdu3aZsCAAY7b+v9ovxISEkxJ/qm6eEv5yy+/XOT6wYMHG3d3d7Nv3z5jjDGnT58248ePN40aNTKenp4mMDDQtGvXzrzyyismLy/PsV1+fr55+eWXTbNmzYynp6cJCgoy3bp1M5s2bXKayxtuuMF4e3ubiIgI8+KLL5q5c+caSebgwYOOfmW9Df6in376yYwePdo0adLEeHt7G19fXxMZGWmef/55k5WV5ehXUFBgnnjiCRMYGGh8fX1NbGys2bdvX7G3wV/qZ2716tVGkrHZbObIkSNF9tm/f78ZNGiQCQ0NNR4eHqZu3brmzjvvNEuWLCnRfgGuYDPmEse8AQAArkJcAwQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHByEWwW6366efflLNmjUv+e3YAADgymGM0enTpxUWFlbo+xJ/jwBUhJ9++knh4eGuLgMAAJTBkSNHdO21116yDwGoCDVr1pT06wT6+fm5uBoAAFAS2dnZCg8Pd3yOXwoBqAgXT3v5+fkRgAAAqGJKcvkKF0EDAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLcWkA+vLLL9WzZ0+FhYXJZrPpww8//MNt1qxZo5tuukleXl5q1KiR5s+fX6jPjBkzFBERIW9vb0VFRWnjxo3lXzwAAKiyXBqAcnJy1KpVK82YMaNE/Q8ePKgePXqoU6dO2rp1qx599FENHTpUq1atcvRJSkpSfHy8EhIStHnzZrVq1UqxsbE6fvx4Re0GAACoYmzGGOPqIqRfv7hs2bJl6t27d7F9nnjiCa1YsULbt293tN17773KzMxUcnKyJCkqKko333yz3nzzTUmS3W5XeHi4/va3v2ncuHElqiU7O1v+/v7Kysoq1y9DNcbo3IWCchsPAICqyMfDvURfWFpapfn8rlLfBp+amqqYmBinttjYWD366KOSpLy8PG3atEnjx493rHdzc1NMTIxSU1OLHTc3N1e5ubmO19nZ2eVb+P937kKBmk9a9ccdAQC4irWpV0uLh0VXSAgqqSp1EXR6erpCQkKc2kJCQpSdna1z587p5MmTKigoKLJPenp6seMmJibK39/fsYSHh1dI/QAAQPru8C8uPyNSpY4AVZTx48crPj7e8To7O7tCQpCPh7t2TI4t93EBAKgKzuYVqM1zn7m6DElVLACFhoYqIyPDqS0jI0N+fn7y8fGRu7u73N3di+wTGhpa7LheXl7y8vKqkJp/y2azydezSk05AABXpSp1Ciw6OlopKSlObatXr1Z0dLQkydPTU5GRkU597Ha7UlJSHH0AAABcGoDOnDmjrVu3auvWrZJ+vc1969atSktLk/TrqalBgwY5+g8bNkwHDhzQ2LFjtWvXLr311lt6//33NXr0aEef+Ph4zZ49WwsWLNDOnTs1fPhw5eTkaMiQIZW6bwAA4Mrl0vMx3333nTp16uR4ffE6nLi4OM2fP1/Hjh1zhCFJql+/vlasWKHRo0dr+vTpuvbaa/WPf/xDsbH/u66mb9++OnHihCZNmqT09HS1bt1aycnJhS6MBgAA1nXFPAfoSlJRzwECAMDKzublOx4Hs2NybLlfF1uaz+8qdQ0QAABAeSAAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAy3F5AJoxY4YiIiLk7e2tqKgobdy4sdi+Fy5c0OTJk9WwYUN5e3urVatWSk5Odurz9NNPy2azOS3NmjWr6N0AAABViEsDUFJSkuLj45WQkKDNmzerVatWio2N1fHjx4vsP2HCBL399tt64403tGPHDg0bNkx9+vTRli1bnPq1aNFCx44dcyzr1q2rjN0BAABVhEsD0NSpU/Xggw9qyJAhat68uWbNmiVfX1/NnTu3yP7vvvuunnzySXXv3l0NGjTQ8OHD1b17d7366qtO/apVq6bQ0FDHEhgYWBm7AwAAqgiXBaC8vDxt2rRJMTEx/yvGzU0xMTFKTU0tcpvc3Fx5e3s7tfn4+BQ6wrN3716FhYWpQYMGGjBggNLS0i5ZS25urrKzs50WAABw9XJZADp58qQKCgoUEhLi1B4SEqL09PQit4mNjdXUqVO1d+9e2e12rV69WkuXLtWxY8ccfaKiojR//nwlJydr5syZOnjwoDp06KDTp08XW0tiYqL8/f0dS3h4ePnsJAAAuCK5/CLo0pg+fboaN26sZs2aydPTU6NGjdKQIUPk5va/3ejWrZvuvvtu3XDDDYqNjdXKlSuVmZmp999/v9hxx48fr6ysLMdy5MiRytgdAADgIi4LQIGBgXJ3d1dGRoZTe0ZGhkJDQ4vcJigoSB9++KFycnJ0+PBh7dq1SzVq1FCDBg2KfZ+AgAA1adJE+/btK7aPl5eX/Pz8nBYAAHD1clkA8vT0VGRkpFJSUhxtdrtdKSkpio6OvuS23t7eqlu3rvLz8/XBBx+oV69exfY9c+aM9u/frzp16pRb7QAAoGpz6Smw+Ph4zZ49WwsWLNDOnTs1fPhw5eTkaMiQIZKkQYMGafz48Y7+33zzjZYuXaoDBw7oq6++UteuXWW32zV27FhHnzFjxmjt2rU6dOiQ1q9frz59+sjd3V39+vWr9P0DAABXpmqufPO+ffvqxIkTmjRpktLT09W6dWslJyc7LoxOS0tzur7n/PnzmjBhgg4cOKAaNWqoe/fuevfddxUQEODo8+OPP6pfv346deqUgoKC1L59e23YsEFBQUGVvXsAAOAKZTPGGFcXcaXJzs6Wv7+/srKyuB4IAIBycjYvX80nrZIk7ZgcK1/P8j0OU5rP7yp1FxgAAEB5IAABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLcXkAmjFjhiIiIuTt7a2oqCht3Lix2L4XLlzQ5MmT1bBhQ3l7e6tVq1ZKTk6+rDEBAID1uDQAJSUlKT4+XgkJCdq8ebNatWql2NhYHT9+vMj+EyZM0Ntvv6033nhDO3bs0LBhw9SnTx9t2bKlzGMCAADrsRljjKvePCoqSjfffLPefPNNSZLdbld4eLj+9re/ady4cYX6h4WF6amnntLIkSMdbXfddZd8fHz0r3/9q0xjFiU7O1v+/v7KysqSn5/f5e4mAACQdDYvX80nrZIk7ZgcK1/PauU6fmk+v112BCgvL0+bNm1STEzM/4pxc1NMTIxSU1OL3CY3N1fe3t5ObT4+Plq3bl2ZxwQAANbjsgB08uRJFRQUKCQkxKk9JCRE6enpRW4TGxurqVOnau/evbLb7Vq9erWWLl2qY8eOlXlM6ddglZ2d7bQAAICrl8svgi6N6dOnq3HjxmrWrJk8PT01atQoDRkyRG5ul7cbiYmJ8vf3dyzh4eHlVDEAALgSuSwABQYGyt3dXRkZGU7tGRkZCg0NLXKboKAgffjhh8rJydHhw4e1a9cu1ahRQw0aNCjzmJI0fvx4ZWVlOZYjR45c5t4BAIArmcsCkKenpyIjI5WSkuJos9vtSklJUXR09CW39fb2Vt26dZWfn68PPvhAvXr1uqwxvby85Ofn57QAAICrV/lefl1K8fHxiouLU5s2bdS2bVtNmzZNOTk5GjJkiCRp0KBBqlu3rhITEyVJ33zzjY4eParWrVvr6NGjevrpp2W32zV27NgSjwkAAODSANS3b1+dOHFCkyZNUnp6ulq3bq3k5GTHRcxpaWlO1/ecP39eEyZM0IEDB1SjRg11795d7777rgICAko8JgAAgEufA3Sl4jlAAACUP54DBAAA4EIEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDnVyrJRQUGB5s+fr5SUFB0/flx2u91p/eeff14uxQEAAFSEMgWgRx55RPPnz1ePHj10/fXXy2azlXddAAAAFaZMAWjRokV6//331b179/KuBwAAoMKV6RogT09PNWrUqLxrAQAAqBRlCkCPPfaYpk+fLmNMedcDAABQ4cp0CmzdunX64osv9Mknn6hFixby8PBwWr906dJyKQ4AAKAilOkIUEBAgPr06aOOHTsqMDBQ/v7+TktpzJgxQxEREfL29lZUVJQ2btx4yf7Tpk1T06ZN5ePjo/DwcI0ePVrnz593rH/66adls9mclmbNmpVlNwEAwFWqTEeA5s2bVy5vnpSUpPj4eM2aNUtRUVGaNm2aYmNjtXv3bgUHBxfq/95772ncuHGaO3eu2rVrpz179mjw4MGy2WyaOnWqo1+LFi302WefOV5Xq1am3QQAAFepy0oGJ06c0O7duyVJTZs2VVBQUKm2nzp1qh588EENGTJEkjRr1iytWLFCc+fO1bhx4wr1X79+vW655Rb1799fkhQREaF+/frpm2++cepXrVo1hYaGlmWXAACABZTpFFhOTo7uv/9+1alTR7feeqtuvfVWhYWF6YEHHtDZs2dLNEZeXp42bdqkmJiY/xXj5qaYmBilpqYWuU27du20adMmx2myAwcOaOXKlYVux9+7d6/CwsLUoEEDDRgwQGlpaZesJTc3V9nZ2U4LAAC4epUpAMXHx2vt2rX66KOPlJmZqczMTP3nP//R2rVr9dhjj5VojJMnT6qgoEAhISFO7SEhIUpPTy9ym/79+2vy5Mlq3769PDw81LBhQ91222168sknHX2ioqI0f/58JScna+bMmTp48KA6dOig06dPF1tLYmKi0zVM4eHhJdoHAABQNZUpAH3wwQeaM2eOunXrJj8/P/n5+al79+6aPXu2lixZUt41OqxZs0ZTpkzRW2+9pc2bN2vp0qVasWKFnn32WUefbt266e6779YNN9yg2NhYrVy5UpmZmXr//feLHXf8+PHKyspyLEeOHKmwfQAAAK5XpmuAzp49W+jIjSQFBweX+BRYYGCg3N3dlZGR4dSekZFR7PU7EydO1MCBAzV06FBJUsuWLZWTk6OHHnpITz31lNzcCue5gIAANWnSRPv27Su2Fi8vL3l5eZWobgAAUPWV6QhQdHS0EhISnG4/P3funJ555hlFR0eXaAxPT09FRkYqJSXF0Wa325WSklLsGGfPni0Uctzd3SWp2IcynjlzRvv371edOnVKVBcAALj6lekI0PTp0xUbG6trr71WrVq1kiRt27ZN3t7eWrVqVYnHiY+PV1xcnNq0aaO2bdtq2rRpysnJcdwVNmjQINWtW1eJiYmSpJ49e2rq1Km68cYbFRUVpX379mnixInq2bOnIwiNGTNGPXv2VL169fTTTz8pISFB7u7u6tevX1l2FQAAXIXKFICuv/567d27VwsXLtSuXbskSf369dOAAQPk4+NT4nH69u2rEydOaNKkSUpPT1fr1q2VnJzsOL2WlpbmdMRnwoQJstlsmjBhgo4ePaqgoCD17NlTzz//vKPPjz/+qH79+unUqVMKCgpS+/bttWHDhlLfog8AAK5eNsMXehWSnZ0tf39/ZWVlyc/Pz9XlAABwVTibl6/mk349U7Rjcqx8Pcv3QcWl+fwu8TsvX75c3bp1k4eHh5YvX37Jvn/+859LOiwAAEClK3EA6t27t9LT0xUcHKzevXsX289ms6mgoKA8agMAAKgQJQ5Adru9yD8DAABUNWW6Db4omZmZ5TUUAABAhSpTAHrxxReVlJTkeH333Xerdu3aqlu3rrZt21ZuxQEAAFSEMgWgWbNmOb4va/Xq1frss8+UnJysbt266fHHHy/XAgEAAMpbme4/S09PdwSgjz/+WPfcc4+6dOmiiIgIRUVFlWuBAAAA5a1MR4Bq1arl+MLQ5ORkxcTESPr16yi4AwwAAFzpynQE6C9/+Yv69++vxo0b69SpU+rWrZskacuWLWrUqFG5FggAAFDeyhSAXnvtNUVEROjIkSN66aWXVKNGDUnSsWPHNGLEiHItEAAAoLyVKQB5eHhozJgxhdpHjx592QUBAABUNL4KAwAAWA5fhQEAACyHr8IAAACWU25fhQEAAFBVlCkA/f3vf9frr79eqP3NN9/Uo48+erk1AQAAVKgyBaAPPvhAt9xyS6H2du3aacmSJZddFAAAQEUqUwA6deqU/P39C7X7+fnp5MmTl10UAABARSpTAGrUqJGSk5MLtX/yySdq0KDBZRcFAABQkcr0IMT4+HiNGjVKJ06c0O233y5JSklJ0auvvqpp06aVZ30AAADlrkwB6P7771dubq6ef/55Pfvss5KkiIgIzZw5U4MGDSrXAgEAAMpbmQKQJA0fPlzDhw/XiRMn5OPj4/g+MAAAgCtdmZ8DlJ+fr88++0xLly6VMUaS9NNPP+nMmTPlVhwAAEBFKNMRoMOHD6tr165KS0tTbm6uOnfurJo1a+rFF19Ubm6uZs2aVd51AgAAlJsyHQF65JFH1KZNG/3yyy/y8fFxtPfp00cpKSnlVhwAAEBFKNMRoK+++krr16+Xp6enU3tERISOHj1aLoUBAABUlDIdAbLb7UV+4/uPP/6omjVrXnZRAAAAFalMAahLly5Oz/ux2Ww6c+aMEhIS1L179/KqDQAAoEKU6RTYK6+8oq5du6p58+Y6f/68+vfvr7179yowMFD//ve/y7tGAACAclWmABQeHq5t27YpKSlJ27Zt05kzZ/TAAw9owIABThdFAwAAXIlKHYAuXLigZs2a6eOPP9aAAQM0YMCAiqgLAACgwpT6GiAPDw+dP3++ImoBAACoFGW6CHrkyJF68cUXlZ+fX971AAAAVLgyXQP07bffKiUlRZ9++qlatmyp6tWrO61funRpuRQHAABQEcoUgAICAnTXXXeVdy0AAACVolQByG636+WXX9aePXuUl5en22+/XU8//TR3fgEAgCqlVNcAPf/883ryySdVo0YN1a1bV6+//rpGjhxZUbUBAABUiFIFoH/+85966623tGrVKn344Yf66KOPtHDhQtnt9oqqDwAAoNyVKgClpaU5fdVFTEyMbDabfvrpp3IvDAAAoKKUKgDl5+fL29vbqc3Dw0MXLlwocwEzZsxQRESEvL29FRUVpY0bN16y/7Rp09S0aVP5+PgoPDxco0ePLvRcotKOCQAArKVUF0EbYzR48GB5eXk52s6fP69hw4Y53Qpf0tvgk5KSFB8fr1mzZikqKkrTpk1TbGysdu/ereDg4EL933vvPY0bN05z585Vu3bttGfPHg0ePFg2m01Tp04t05gAAMB6bMYYU9LOQ4YMKVG/efPmlahfVFSUbr75Zr355puSfr3LLDw8XH/72980bty4Qv1HjRqlnTt3KiUlxdH22GOP6ZtvvtG6devKNGZRsrOz5e/vr6ysLPn5+ZVoGwAAcGln8/LVfNIqSdKOybHy9SzT03iKVZrP71K9c0mDTUnk5eVp06ZNGj9+vKPNzc1NMTExSk1NLXKbdu3a6V//+pc2btyotm3b6sCBA1q5cqUGDhxY5jEBAID1lG/0KoWTJ0+qoKBAISEhTu0hISHatWtXkdv0799fJ0+eVPv27WWMUX5+voYNG6Ynn3yyzGNKUm5urnJzcx2vs7Ozy7pbAACgCijTd4G5ypo1azRlyhS99dZb2rx5s5YuXaoVK1bo2WefvaxxExMT5e/v71jCw8PLqWIAAHAlctkRoMDAQLm7uysjI8OpPSMjQ6GhoUVuM3HiRA0cOFBDhw6VJLVs2VI5OTl66KGH9NRTT5VpTEkaP3684uPjHa+zs7MJQQAAXMVcdgTI09NTkZGRThc02+12paSkKDo6ushtzp49Kzc355Ld3d0l/XqHWlnGlCQvLy/5+fk5LQAA4OrlsiNAkhQfH6+4uDi1adNGbdu21bRp05STk+O422zQoEGqW7euEhMTJUk9e/bU1KlTdeONNyoqKkr79u3TxIkT1bNnT0cQ+qMxAQAAXBqA+vbtqxMnTmjSpElKT09X69atlZyc7LiIOS0tzemIz4QJE2Sz2TRhwgQdPXpUQUFB6tmzp55//vkSjwkAAFCq5wBZBc8BAgCg/F1JzwGqUneBAQAAlAcCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsJwrIgDNmDFDERER8vb2VlRUlDZu3Fhs39tuu002m63Q0qNHD0efwYMHF1rftWvXytgVAABQBVRzdQFJSUmKj4/XrFmzFBUVpWnTpik2Nla7d+9WcHBwof5Lly5VXl6e4/WpU6fUqlUr3X333U79unbtqnnz5jlee3l5VdxOAACAKsXlR4CmTp2qBx98UEOGDFHz5s01a9Ys+fr6au7cuUX2r127tkJDQx3L6tWr5evrWygAeXl5OfWrVatWZewOAACoAlwagPLy8rRp0ybFxMQ42tzc3BQTE6PU1NQSjTFnzhzde++9ql69ulP7mjVrFBwcrKZNm2r48OE6depUsWPk5uYqOzvbaQEAAFcvlwagkydPqqCgQCEhIU7tISEhSk9P/8PtN27cqO3bt2vo0KFO7V27dtU///lPpaSk6MUXX9TatWvVrVs3FRQUFDlOYmKi/P39HUt4eHjZdwoAAFzxXH4N0OWYM2eOWrZsqbZt2zq133vvvY4/t2zZUjfccIMaNmyoNWvW6I477ig0zvjx4xUfH+94nZ2dTQgCAOAq5tIjQIGBgXJ3d1dGRoZTe0ZGhkJDQy+5bU5OjhYtWqQHHnjgD9+nQYMGCgwM1L59+4pc7+XlJT8/P6cFAABcvVwagDw9PRUZGamUlBRHm91uV0pKiqKjoy+57eLFi5Wbm6v77rvvD9/nxx9/1KlTp1SnTp3LrhkAAFR9Lr8LLD4+XrNnz9aCBQu0c+dODR8+XDk5ORoyZIgkadCgQRo/fnyh7ebMmaPevXvrmmuucWo/c+aMHn/8cW3YsEGHDh1SSkqKevXqpUaNGik2NrZS9gkAAFzZXH4NUN++fXXixAlNmjRJ6enpat26tZKTkx0XRqelpcnNzTmn7d69W+vWrdOnn35aaDx3d3f997//1YIFC5SZmamwsDB16dJFzz77LM8CAgAAkiSbMca4uogrTXZ2tvz9/ZWVlcX1QAAAlJOzeflqPmmVJGnH5Fj5epbvcZjSfH67/BQYAABAZSMAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAy7kiAtCMGTMUEREhb29vRUVFaePGjcX2ve2222Sz2QotPXr0cPQxxmjSpEmqU6eOfHx8FBMTo71791bGrgAAgCrA5QEoKSlJ8fHxSkhI0ObNm9WqVSvFxsbq+PHjRfZfunSpjh075li2b98ud3d33X333Y4+L730kl5//XXNmjVL33zzjapXr67Y2FidP3++snYLAABcwVwegKZOnaoHH3xQQ4YMUfPmzTVr1iz5+vpq7ty5RfavXbu2QkNDHcvq1avl6+vrCEDGGE2bNk0TJkxQr169dMMNN+if//ynfvrpJ3344YeVuGcAAOBK5dIAlJeXp02bNikmJsbR5ubmppiYGKWmppZojDlz5ujee+9V9erVJUkHDx5Uenq605j+/v6Kiooqdszc3FxlZ2c7LQAA4Orl0gB08uRJFRQUKCQkxKk9JCRE6enpf7j9xo0btX37dg0dOtTRdnG70oyZmJgof39/xxIeHl7aXQEAAFWIy0+BXY45c+aoZcuWatu27WWNM378eGVlZTmWI0eOlFOFAADgSuTSABQYGCh3d3dlZGQ4tWdkZCg0NPSS2+bk5GjRokV64IEHnNovbleaMb28vOTn5+e0AACAq5dLA5Cnp6ciIyOVkpLiaLPb7UpJSVF0dPQlt128eLFyc3N13333ObXXr19foaGhTmNmZ2frm2+++cMxAQCANVRzdQHx8fGKi4tTmzZt1LZtW02bNk05OTkaMmSIJGnQoEGqW7euEhMTnbabM2eOevfurWuuucap3Waz6dFHH9Vzzz2nxo0bq379+po4caLCwsLUu3fvytotAABwBXN5AOrbt69OnDihSZMmKT09Xa1bt1ZycrLjIua0tDS5uTkfqNq9e7fWrVunTz/9tMgxx44dq5ycHD300EPKzMxU+/btlZycLG9v7wrfHwAAcOWzGWOMq4u40mRnZ8vf319ZWVlcDwQAQDk5m5ev5pNWSZJ2TI6Vr2f5Hocpzed3lb4LDAAAoCwIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHJc/mWoVZUxRvn5+SooKHB1KcBVy93dXdWqVZPNZnN1KQCuMgSgMsjLy9OxY8d09uxZV5cCXPV8fX1Vp04deXp6uroUAFcRAlAp2e12HTx4UO7u7goLC5Onpyf/OwUqgDFGeXl5OnHihA4ePKjGjRvLzY2z9gDKBwGolPLy8mS32xUeHi5fX19XlwNc1Xx8fOTh4aHDhw8rLy9P3t7eri4JwFWC/06VEf8TBSoHv2sAKgL/sgAAAMshAAEAAMshAMGyUlJS9Kc//YlHGQCABRGALGLw4MGy2Wyy2Wzy9PRUo0aNNHnyZOXn50uS1qxZ41hvs9kUFBSk7t276/vvv//DsY0xeueddxQVFaUaNWooICBAbdq00bRp067oRwWMHTtWEyZMkLu7u1P7uXPnVLt2bQUGBio3N7fQdjabTR9++GGh9sGDB6t3795Obfv27dOQIUN07bXXysvLS/Xr11e/fv303XffleeuOPnyyy/Vs2dPhYWFFVtrUdasWaObbrpJXl5eatSokebPn1+oz4wZMxQRESFvb29FRUVp48aNTuvPnz+vkSNH6pprrlGNGjV01113KSMjw6lPWlqaevToIV9fXwUHB+vxxx93/BwCQGUhAFlI165ddezYMe3du1ePPfaYnn76ab388stOfXbv3q1jx45p1apVys3NVY8ePZSXl3fJcQcOHKhHH31UvXr10hdffKGtW7dq4sSJ+s9//qNPP/20zPX+0ftejnXr1mn//v266667Cq374IMP1KJFCzVr1qzE4aEo3333nSIjI7Vnzx69/fbb2rFjh5YtW6ZmzZrpscceu4zqLy0nJ0etWrXSjBkzSrzNwYMH1aNHD3Xq1Elbt27Vo48+qqFDh2rVqlWOPklJSYqPj1dCQoI2b96sVq1aKTY2VsePH3f0GT16tD766CMtXrxYa9eu1U8//aS//OUvjvUFBQWOn6n169drwYIFmj9/viZNmlQ+Ow8AJWVQSFZWlpFksrKyCq07d+6c2bFjhzl37pyjzW63m5zcC5W+2O32Eu9TXFyc6dWrl1Nb586dzf/93/8ZY4z54osvjCTzyy+/ONYvX77cSDLbtm0rdtykpCQjyXz44YeF1tntdpOZmWmMMaZjx47mkUcecVrfq1cvExcX53hdr149M3nyZDNw4EBTs2ZNExcXZ6Kjo83YsWOdtjt+/LipVq2aWbt2rTHGmPPnz5vHHnvMhIWFGV9fX9O2bVvzxRdfXHI+Ro4caf76178Wue62224zs2bNMjNnzjSdO3cutF6SWbZsWaH2386x3W43LVq0MJGRkaagoKBQ39/Oc0UqrtbfGzt2rGnRooVTW9++fU1sbKzjddu2bc3IkSMdrwsKCkxYWJhJTEw0xhiTmZlpPDw8zOLFix19du7caSSZ1NRUY4wxK1euNG5ubiY9Pd3RZ+bMmcbPz8/k5uYWWVtRv3MAqqac3Aum3hMfm3pPfGxyci+U+/iX+vz+PZ4DVA7OXShQ80mr/rhjOdsxOVa+nmX/K/Tx8dGpU6eKXJeVlaVFixZJ0iWfwLtw4UI1bdpUvXr1KrTOZrPJ39+/VDW98sormjRpkhISEiRJycnJeumll/TCCy84HjiZlJSksLAwdejQQZI0atQo7dixQ4sWLVJYWJiWLVumrl276vvvv1fjxo2LfJ+vvvpK/fv3L9S+f/9+paamaunSpTLGaPTo0Tp8+LDq1atXqv3YunWrfvjhB7333ntF3sYdEBBQ7LZTpkzRlClTLjn+jh07dN1115WqpktJTU1VTEyMU1tsbKweffRRSb8ejdu0aZPGjx/vWO/m5qaYmBilpqZKkjZt2qQLFy44jdOsWTNdd911Sk1N1f/93/8pNTVVLVu2VEhIiNP7DB8+XD/88INuvPHGctsnALgUApAFGWOUkpKiVatW6W9/+5vTumuvvVbSr6dRJOnPf/6zmjVrVuxYe/fuVdOmTcuttttvv93p9NA999yjRx99VOvWrXMEnvfee0/9+vWTzWZTWlqa5s2bp7S0NIWFhUmSxowZo+TkZM2bN6/YIHH48GFH/9+aO3euunXrplq1akn69cN53rx5evrpp0u1H3v37pWkS85dcYYNG6Z77rnnkn2Kqv1ypKenO4USSQoJCVF2drbOnTunX375RQUFBUX22bVrl2MMT0/PQuEuJCRE6enpl3yfi+sAoLIQgMqBj4e7dkyOdcn7lsbHH3+sGjVq6MKFC7Lb7erfv3+hD/avvvpKvr6+2rBhg6ZMmaJZs2ZdckxjTGnLvqQ2bdo4vQ4KClKXLl20cOFCdejQQQcPHlRqaqrefvttSdL333+vgoICNWnSxGm73NxcXXPNNcW+z7lz5wo9VbigoEALFizQ9OnTHW333XefxowZo0mTJpXqgXyXMy+1a9dW7dq1y7w9AOCPEYDKgc1mu6xTUZWlU6dOmjlzpjw9PRUWFqZq1QrXXL9+fQUEBKhp06Y6fvy4+vbtqy+//LLYMZs0aeI4AnApbm5uhULBhQsXCvWrXr16obYBAwbo73//u9544w299957atmypVq2bClJOnPmjNzd3bVp06ZCd3PVqFGj2HoCAwP1yy+/OLWtWrVKR48eVd++fZ3aCwoKlJKSos6dO0uSatasqaysrEJjZmZmOk75XQxku3btKvVpHVecAgsNDS10t1ZGRob8/Pzk4+Mjd3d3ubu7F9knNDTUMUZeXp4yMzOdjgL9vs/v7xy7OObFPgBQGbgLzEKqV6+uRo0a6brrrisy/PzeyJEjtX37di1btqzYPv3799eePXv0n//8p9A6Y4wjKAQFBenYsWOOdQUFBdq+fXuJ6u7Vq5fOnz+v5ORkvffeexowYIBj3Y033qiCggIdP35cjRo1clou9YF64403aseOHU5tc+bM0b333qutW7c6Lffee6/mzJnj6Ne0aVNt2rTJaduCggJt27bNEXxat26t5s2b69VXX5Xdbi/0/pmZmcXWNmzYsEI1/H4p71Ng0dHRSklJcWpbvXq1oqOjJf16HVhkZKRTH7vdrpSUFEefyMhIeXh4OPXZvXu30tLSHH2io6P1/fffO905tnr1avn5+al58+bluk8AcEnlfgn2VaC0d4FVBUXdBfZbRd0FZsyvdwe1bNmy2DvO7Ha76du3r/Hx8THPP/+8+fbbb82hQ4fMRx99ZG6//XbHHUizZs0yvr6+5uOPPzY7d+40Dz74oPHz8yt0F9hrr71W5PsMGDDAtGrVythsNnP48OFC6yIiIswHH3xgDhw4YL755hszZcoU8/HHHxe7v6+//rqJjIx0vD5+/Ljx8PAwn3zySaG+K1euNF5eXubUqVPGGGPee+894+PjY2bMmGH27NljtmzZYu6//37j7+/vdHfTN998Y2rWrGnatWtnVqxYYfbv32+2bdtmnnvuOXPrrbcWW9vlOn36tNmyZYvZsmWLkWSmTp1qtmzZ4jRv48aNMwMHDnS8PnDggPH19TWPP/642blzp5kxY4Zxd3c3ycnJjj6LFi0yXl5eZv78+WbHjh3moYceMgEBAU77PGzYMHPdddeZzz//3Hz33XcmOjraREdHO9bn5+eb66+/3nTp0sVs3brVJCcnm6CgIDN+/Phi96eq/s4BKOxKuguMAFQEAtD/pKWlmWrVqpmkpKRity0oKDAzZ840N998s/H19TV+fn4mMjLSTJ8+3Zw9e9YYY0xeXp4ZPny4qV27tgkODjaJiYlF3gZfXABauXKlkVRkcMjLyzOTJk0yERERxsPDw9SpU8f06dPH/Pe//y225lOnThlvb2+za9cuY4wxr7zyigkICDB5eXmF+ubm5pqAgAAzffp0R9vChQtNZGSkqVmzpgkJCTHdu3cv8nEBu3fvNoMGDTJhYWHG09PT1KtXz/Tr189s3ry52Nou18W/y98vv53ruLg407Fjx0LbtW7d2nh6epoGDRqYefPmFRr7jTfeMNddd53x9PQ0bdu2NRs2bHBaf+7cOTNixAhTq1Yt4+vra/r06WOOHTvm1OfQoUOmW7duxsfHxwQGBprHHnvMXLhQ/D+EVfV3DkBhv31sTGke5VJSpQlANmPK+SrWq0B2drb8/f2VlZUlPz8/p3Xnz5/XwYMHVb9+/UIX0aJqefzxx5Wdne24oBpXJn7nAJTUpT6/f49rgGBZTz31lOrVq1fkNToAgKvblX/rElBBAgIC9OSTT7q6DACAC3AECAAAWA4BCAAAWA4BqIy4dhyoHPyuAagIBKBS8vDwkCSdPXvWxZUA1nDxd+3i7x4AlAcugi4ld3d3BQQEOJ5k6+vr6/iWcgDlxxijs2fP6vjx4woICCj0VScAcDkIQGVw8SsWfvs4fwAVIyAggO8JA1DuCEBlYLPZVKdOHQUHBxf5hZ4AyoeHhwdHfgBUCJcHoBkzZujll19Wenq6WrVqpTfeeENt27Yttn9mZqaeeuopLV26VD///LPq1aunadOmqXv37pKkp59+Ws8884zTNk2bNi3RN5aX1sVvyAYAAFWLSwNQUlKS4uPjNWvWLEVFRWnatGmKjY3V7t27FRwcXKh/Xl6eOnfurODgYC1ZskR169bV4cOHFRAQ4NSvRYsW+uyzzxyvS/LN5wAAwDpcmgymTp2qBx98UEOGDJEkzZo1SytWrNDcuXM1bty4Qv3nzp2rn3/+WevXr3fcERIREVGoX7Vq1bhmAAAAFMtlt8Hn5eVp06ZNiomJ+V8xbm6KiYlRampqkdssX75c0dHRGjlypEJCQnT99ddrypQpKigocOq3d+9ehYWFqUGDBhowYIDS0tIqdF8AAEDV4rIjQCdPnlRBQYFCQkKc2kNCQoq9XufAgQP6/PPPNWDAAK1cuVL79u3TiBEjdOHCBSUkJEiSoqKiNH/+fDVt2lTHjh3TM888ow4dOmj79u2qWbNmkePm5uYqNzfX8TorK0vSr98qCwAAqoaLn9sleoCqcZGjR48aSWb9+vVO7Y8//rhp27Ztkds0btzYhIeHm/z8fEfbq6++akJDQ4t9n19++cX4+fmZf/zjH8X2SUhIMJJYWFhYWFhYroLlyJEjf5hDXHYEKDAwUO7u7srIyHBqz8jIKPb6nTp16hS6LfZPf/qT0tPTlZeXJ09Pz0LbBAQEqEmTJtq3b1+xtYwfP17x8fGO13a7XT///LOuueaacn/IYXZ2tsLDw3XkyBH5+fmV69j4H+a5cjDPlYN5rhzMc+WoyHk2xuj06dMKCwv7w74uC0Cenp6KjIxUSkqKevfuLenX4JGSkqJRo0YVuc0tt9yi9957T3a7XW5uv16+tGfPHtWpU6fI8CNJZ86c0f79+zVw4MBia/Hy8pKXl5dT2+/vLCtvfn5+/IJVAua5cjDPlYN5rhzMc+WoqHn29/cvUT+XfhdYfHy8Zs+erQULFmjnzp0aPny4cnJyHHeFDRo0SOPHj3f0Hz58uH7++Wc98sgj2rNnj1asWKEpU6Zo5MiRjj5jxozR2rVrdejQIa1fv159+vSRu7u7+vXrV+n7BwAArkwuvQ2+b9++OnHihCZNmqT09HS1bt1aycnJjguj09LSHEd6JCk8PFyrVq3S6NGjdcMNN6hu3bp65JFH9MQTTzj6/Pjjj+rXr59OnTqloKAgtW/fXhs2bFBQUFCl7x8AALgyufwJgaNGjSr2lNeaNWsKtUVHR2vDhg3Fjrdo0aLyKq1CeHl5KSEhodApN5Qv5rlyMM+Vg3muHMxz5bhS5tlmTEnuFQMAALh6uPQaIAAAAFcgAAEAAMshAAEAAMshAAEAAMshAFWAGTNmKCIiQt7e3oqKitLGjRsv2X/x4sVq1qyZvL291bJlS61cubKSKq3aSjPPs2fPVocOHVSrVi3VqlVLMTExf/j3gl+V9uf5okWLFslmszkedIpLK+08Z2ZmauTIkapTp468vLzUpEkT/u0ogdLO87Rp09S0aVP5+PgoPDxco0eP1vnz5yup2qrpyy+/VM+ePRUWFiabzaYPP/zwD7dZs2aNbrrpJnl5ealRo0aaP39+hdfpsu8Cu1otWrTIeHp6mrlz55offvjBPPjggyYgIMBkZGQU2f/rr7827u7u5qWXXjI7duwwEyZMMB4eHub777+v5MqrltLOc//+/c2MGTPMli1bzM6dO83gwYONv7+/+fHHHyu58qqltPN80cGDB03dunVNhw4dTK9evSqn2CqstPOcm5tr2rRpY7p3727WrVtnDh48aNasWWO2bt1ayZVXLaWd54ULFxovLy+zcOFCc/DgQbNq1SpTp04dM3r06EquvGpZuXKleeqpp8zSpUuNJLNs2bJL9j9w4IDx9fU18fHxZseOHeaNN94w7u7uJjk5uULrJACVs7Zt25qRI0c6XhcUFJiwsDCTmJhYZP977rnH9OjRw6ktKirKPPzwwxVaZ1VX2nn+vfz8fFOzZk2zYMGCiirxqlCWec7Pzzft2rUz//jHP0xcXBwBqARKO88zZ840DRo0MHl5eZVV4lWhtPM8cuRIc/vttzu1xcfHm1tuuaVC67yalCQAjR071rRo0cKprW/fviY2NrYCKzOGU2DlKC8vT5s2bVJMTIyjzc3NTTExMUpNTS1ym9TUVKf+khQbG1tsf5Rtnn/v7NmzunDhgmrXrl1RZVZ5ZZ3nyZMnKzg4WA888EBllFnllWWely9frujoaI0cOVIhISG6/vrrNWXKFBUUFFRW2VVOWea5Xbt22rRpk+M02YEDB7Ry5Up17969Umq2Cld9Drr8SdBXk5MnT6qgoMDxVR4XhYSEaNeuXUVuk56eXmT/9PT0CquzqivLPP/eE088obCwsEK/dPifsszzunXrNGfOHG3durUSKrw6lGWeDxw4oM8//1wDBgzQypUrtW/fPo0YMUIXLlxQQkJCZZRd5ZRlnvv376+TJ0+qffv2MsYoPz9fw4YN05NPPlkZJVtGcZ+D2dnZOnfunHx8fCrkfTkCBMt54YUXtGjRIi1btkze3t6uLueqcfr0aQ0cOFCzZ89WYGCgq8u5qtntdgUHB+udd95RZGSk+vbtq6eeekqzZs1ydWlXlTVr1mjKlCl66623tHnzZi1dulQrVqzQs88+6+rSUA44AlSOAgMD5e7uroyMDKf2jIwMhYaGFrlNaGhoqfqjbPN80SuvvKIXXnhBn332mW644YaKLLPKK+0879+/X4cOHVLPnj0dbXa7XZJUrVo17d69Ww0bNqzYoqugsvw816lTRx4eHnJ3d3e0/elPf1J6erry8vLk6elZoTVXRWWZ54kTJ2rgwIEaOnSoJKlly5bKycnRQw89pKeeesrpy7pRdsV9Dvr5+VXY0R+JI0DlytPTU5GRkUpJSXG02e12paSkKDo6ushtoqOjnfpL0urVq4vtj7LNsyS99NJLevbZZ5WcnKw2bdpURqlVWmnnuVmzZvr++++1detWx/LnP/9ZnTp10tatWxUeHl6Z5VcZZfl5vuWWW7Rv3z5HwJSkPXv2qE6dOoSfYpRlns+ePVso5FwMnYav0Sw3LvscrNBLrC1o0aJFxsvLy8yfP9/s2LHDPPTQQyYgIMCkp6cbY4wZOHCgGTdunKP/119/bapVq2ZeeeUVs3PnTpOQkMBt8CVQ2nl+4YUXjKenp1myZIk5duyYYzl9+rSrdqFKKO08/x53gZVMaec5LS3N1KxZ04waNcrs3r3bfPzxxyY4ONg899xzrtqFKqG085yQkGBq1qxp/v3vf5sDBw6YTz/91DRs2NDcc889rtqFKuH06dNmy5YtZsuWLUaSmTp1qtmyZYs5fPiwMcaYcePGmYEDBzr6X7wN/vHHHzc7d+40M2bM4Db4quqNN94w1113nfH09DRt27Y1GzZscKzr2LGjiYuLc+r//vvvmyZNmhhPT0/TokULs2LFikquuGoqzTzXq1fPSCq0JCQkVH7hVUxpf55/iwBUcqWd5/Xr15uoqCjj5eVlGjRoYJ5//nmTn59fyVVXPaWZ5wsXLpinn37aNGzY0Hh7e5vw8HAzYsQI88svv1R+4VXIF198UeS/txfnNi4uznTs2LHQNq1btzaenp6mQYMGZt68eRVep80YjuMBAABr4RogAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgACghm82mDz/8UJJ06NAh2Ww2bd261aU1ASgbAhCAKmHw4MGy2Wyy2Wzy8PBQ/fr1NXbsWJ0/f97VpQGogvg2eABVRteuXTVv3jxduHBBmzZtUlxcnGw2m1588UVXlwagiuEIEIAqw8vLS6GhoQoPD1fv3r0VExOj1atXS/r1m70TExNVv359+fj4qFWrVlqyZInT9j/88IPuvPNO+fn5qWbNmurQoYP2798vSfr222/VuXNnBQYGyt/fXx07dtTmzZsrfR8BVA4CEIAqafv27Vq/fr08PT0lSYmJifrnP/+pWbNm6YcfftDo0aN13333ae3atZKko0eP6tZbb5WXl5c+//xzbdq0Sffff7/y8/MlSadPn1ZcXJzWrVunDRs2qHHjxurevbtOnz7tsn0EUHE4BQagyvj4449Vo0YN5efnKzc3V25ubnrzzTeVm5urKVOm6LPPPlN0dLQkqUGDBlq3bp3efvttdezYUTNmzJC/v78WLVokDw8PSVKTJk0cY99+++1O7/XOO+8oICBAa9eu1Z133ll5OwmgUhCAAFQZnTp10syZM5WTk6PXXntN1apV01133aUffvhBZ8+eVefOnZ365+Xl6cYbb5Qkbd26VR06dHCEn9/LyMjQhAkTtGbNGh0/flwFBQU6e/as0tLSKny/AFQ+AhCAKqN69epq1KiRJGnu3Llq1aqV5syZo+uvv16StGLFCtWtW9dpGy8vL0mSj4/PJceOi4vTqVOnNH36dNWrV09eXl6Kjo5WXl5eBewJAFcjAAGoktzc3PTkk08qPj5ee/bskZeXl9LS0tSxY8ci+99www1asGCBLly4UORRoK+//lpvvfWWunfvLkk6cuSITp48WaH7AMB1uAgaQJV19913y93dXW+//bbGjBmj0aNHa8GCBdq/f782b96sN954QwsWLJAkjRo1StnZ2br33nv13Xffae/evXr33Xe1e/duSVLjxo317rvvaufOnfrmm280YMCAPzxqBKDq4ggQgCqrWrVqGjVqlF566SUdPHhQQUFBSkxM1IEDBxQQEKCbbrpJTz75pCTpmmuu0eeff67HH39cHTt2lLu7u1q3bq1bbrlFkjRnzhw99NBDuummmxQeHq4pU6ZozJgxrtw9ABXIZowxri4CAACgMnEKDAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWM7/A5RuzLf/VUrSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate models\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[solver] = accuracy\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print summary of results\n",
        "print(\"\\nAccuracy comparison of different solvers:\")\n",
        "for solver, acc in results.items():\n",
        "    print(f\"{solver}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqfxD2csv1v9",
        "outputId": "c8848016-1838-4fcd-ee1e-53ef6efeb4d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver: liblinear, Accuracy: 0.9737\n",
            "Solver: saga, Accuracy: 0.9737\n",
            "Solver: lbfgs, Accuracy: 0.9737\n",
            "\n",
            "Accuracy comparison of different solvers:\n",
            "liblinear: 0.9737\n",
            "saga: 0.9737\n",
            "lbfgs: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "# Generate synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQkwgnfCwm8T",
        "outputId": "074b7701-b918-4b9e-ca5d-e7ef421b227e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.6593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy on raw data: {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy on standardized data: {accuracy_scaled:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBiKyKPAw7MD",
        "outputId": "07b6ad3c-bc29-4313-e67d-6437ba39fe50"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 0.9561\n",
            "Accuracy on standardized data: 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with cross-validation\n",
        "log_reg_cv = LogisticRegressionCV(cv=5, Cs=10, random_state=42, multi_class='multinomial', max_iter=1000)\n",
        "log_reg_cv.fit(X_train, y_train)\n",
        "\n",
        "# Best C value\n",
        "best_c = log_reg_cv.C_[0]\n",
        "print(f\"Optimal C (Regularization Strength): {best_c}\")\n",
        "\n",
        "# Predictions and accuracy\n",
        "y_pred = log_reg_cv.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-9ehqEBxRu-",
        "outputId": "2bd64826-644a-4b2e-f7f7-f8d86fe6808c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1908: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C (Regularization Strength): 21.54434690031882\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "# Generate synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'logistic_regression_model.pkl')\n",
        "print(\"Model saved successfully.\")\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri_lGUqnxtJZ",
        "outputId": "09a45325-64e0-4161-8c15-8ab61600930a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n",
            "Model loaded successfully.\n",
            "Model Accuracy: 0.83\n"
          ]
        }
      ]
    }
  ]
}